CS373 Final Project
Kyle Pollina, Kurtis Dressel, Zacharie Zirnheld


Introduction
In this analysis, we are taking a look at relationships between images of brain activity captured using FMRI and natural language. This analysis is based off of Predicting Human Brain Activity Associated with the Meanings of Nouns by Tom M. Mitchell in 2008. The goal of this analysis is to train a machine learning algorithm to predict the category of a noun based on the image of brain activity taken when the patient was thinking of said noun. This could give insight into which parts of the brain relate to different concepts.


The Data
For the experiment, each patient was asked to look at an image representing a noun and think about that noun while an FMRI image was taken of their brain activity. This was done 6 times for each of 60 nouns, each noun from 1 of 12 categories. Our dataset consists of 9 patients with 360 images taken for each patient, for a total of 3240 trials. The image size for each patient varied, from around 19000 voxels (for our purposes, features) to around 21000 voxels. We aimed to train two models to predict the noun category based on the image taken of the patient while they were saying that noun.


Data Preprocessing
We decided we would train a support vector machine (SVM) and a K-Nearest-Neighbors (KNN) model on our dataset. In order to reduce the training time we decided to take only half of the trials per patient. Specifically we took the first 3/6 images associated with each of the 60 nouns and their concurrent noun categories as labels. Since these models require that all trials must have the same amount of features, and since each patient’s image varied in size, we had to center truncate each image so that they all matched the size of the smallest image, which was 19750 voxels. For our labels, we hard set labels to be 0-11 based on the noun category that the noun belonged to. We also made sure to shuffle our data so that we can have a random mix of patients for each fold of our cross-validation. 


Cross-Validation
For cross-validation, we split the data 80% training and 20% testing. Within the training data we used 5-fold cross-validation on each model. After folding, we applied PCA to reduce the features from 19750 features down to just the 100 features with the highest variance. 


Training
Since there are more than 2 labels for the dataset, we needed to use a Multi-class classification SVM. After training our SVM classifier on the training set, we tested how good it was on the test set by measuring the precision and recall of the classifier for each word category.
  

Looking at our bar graph, we can see that the SVM was best at predicting nouns that belonged to the vegetable category while we couldn’t accurately predict anything within the vehicle, bodypart, or clothing categories. 


For our KNN model, we needed to tune the parameter K to find out which value of K would yield the lowest error. We looked at K’s from 1 through 20 and found that K=7 produced the lowest validation error. 


  



Once we knew that 7 was the best value for K, we retrained the KNN classifier with a K value of 7 on the training/validation set. Just like the SVM classifier, we measured the precision and recall of the classifier on the test set for each word category.
  



For our final results, we found that our SVM model had an accuracy of 0.060185 and our KNN model had an accuracy of 0.037037. Our models were not very good at predicting the labels based on the images. 




































--------------------------------------------------------------------------------------------------------------


Manual.txt:
In order to run the code, first the latest version of Python3 needs to be installed. The necessary Python libraries are listed in requirements.txt. To install them just run “<python3 executable name> -m pip install --requirement requirements.txt”.


Then, place each file in the dataset folder into the sources folder. This will allow the code to open the mat files.


To run the code, just run “<python3 executable name> main.py” As the code is now, this will train one SVM and KNN classifier and save the necessary graphs. Running KNN hyperparameter tuning takes a long time. If you would like to run hyperparameter tuning, please uncomment the hyperparameter section and then comment the rest of the code in the knn() function.


requirements.txt:
matplotlib==3.0.3   
numpy==1.16.2       
scikit-learn==0.21.3
scipy==1.2.1 




Final TODO list:
Zach:
* Average samples that are of the same word and same person
   * Verify that this is a good idea, that they’re taking a picture of the same thing
* Shuffle averaged samples so that they aren’t simply sorted by person
* Split the data, 20% of it to be a test set, 80% of it to be training/validation for 5foldcv
* Finish 5-fold cross validation
   * For both SVM and kNN
      * kNN should weight labels by distance
   * 5 folds is hard-coded
   * kNN 5foldcv takes in the value of k for kNN so that Kyle can use it for tuning


Signature for each 5 fold cv:
SVM: returns array of errors for each fold, takes in a matrix of samples to perform the cv on and the associated matrix of labels
        ErrorMatrix svm5F(SampleMatrix X, LabelMatrix y)
kNN: returns array of errors for each fold, takes in a matrix of samples to perform the cv on, the associated matrix of labels, and the number of neighbors to consider k
        ErrorMatrix kNN5F(SampleMatrix X, LabelMatrix y, numberOfNeighbors k)


Kurtis:
* Precision and recall plot for the best SVM and KNN model
   * Input is a 12 by 12 numpy matrix where each row is the predicted class and each column is the actual class
   * For example, if on some data with label A the model predicts class B we would need to compute: confusion_matrix[B][A] += 1
   * TODO: make code for confusion_matrix
* For training error and validation error have one line graph for the values of k in KNN
   * Input is two 1 x (# of values of k) numpy matrix where training_error[5] would represent the training error for k=5 and validation_error[5] would be the validation error


Kyle:


* K Nearest Neighbors Hyperparameter tuning (Tune K 1-10 unless error is too small go to 20)
* Record precision and recall for each K
* https://medium.com/datadriveninvestor/k-nearest-neighbors-in-python-hyperparameters-tuning-716734bc557f
* https://en.wikipedia.org/wiki/Precision_and_recall
* https://www.techopedia.com/what-is-precision-and-recall-in-machine-learning/7/33929
* https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall
* https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2






Results:
SVM Accuracy:  0.06018518518518518
KNN Accuracy:  0.037037037037037035
  

  

  



Report Here: